{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"dataset-balanced/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplits = ['train', 'test', 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_targets = {\"train\": {}, \"test\": {}, \"val\": {}}\n",
    "\n",
    "stats_questions = {\"train\": \n",
    "                   {\"exactly\": {\"no\": 0, \"yes\": 0}, \"more\": {\"no\": 0, \"yes\": 0}}, \n",
    "                   \"test\":\n",
    "                   {\"exactly\": {\"no\": 0, \"yes\": 0}, \"more\": {\"no\": 0, \"yes\": 0}}, \n",
    "                   \"val\":\n",
    "                   {\"exactly\": {\"no\": 0, \"yes\": 0}, \"more\": {\"no\": 0, \"yes\": 0}}\n",
    "                  }\n",
    "\n",
    "stats_task = {\"train\": {\"1small2big\": 0, \"1big2small\": 0}, \n",
    "              \"test\": {\"1small2big\": 0, \"1big2small\": 0}, \n",
    "              \"val\": {\"1small2big\": 0, \"1big2small\": 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in datasplits:\n",
    "    with open(annotations_path + \"/\" + split + \".json\") as f:\n",
    "        annotation = json.load(f)\n",
    "        \n",
    "    for sample in annotation[\"questions\"]:\n",
    "        \n",
    "        tokens = sample[\"question\"].split()\n",
    "        \n",
    "        if sample[\"question_index\"] % 6 == 1:\n",
    "            shape = tokens[5]\n",
    "            color = tokens[4]\n",
    "            \n",
    "            if (shape, color) in stats_targets[split]:\n",
    "                stats_targets[split][(shape, color)] += 1\n",
    "            else:\n",
    "                stats_targets[split][(shape, color)] = 1\n",
    "                \n",
    "        stats_task[split][sample[\"task\"]] += 1\n",
    "        \n",
    "        stats_questions[split][tokens[2]][sample[\"answer\"]] += 1\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_index': 0,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There are exactly two green circles that are big circles',\n",
       "  'answer': 'yes',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'},\n",
       " {'question_index': 1,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There is exactly one green circle that is a big circle',\n",
       "  'answer': 'no',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'},\n",
       " {'question_index': 2,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There are more green circles that are big circles',\n",
       "  'answer': 'yes',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'},\n",
       " {'question_index': 3,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There are exactly two green circles that are small circles',\n",
       "  'answer': 'no',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'},\n",
       " {'question_index': 4,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There is exactly one green circle that is a small circle',\n",
       "  'answer': 'yes',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'},\n",
       " {'question_index': 5,\n",
       "  'image_index': 0,\n",
       "  'images': ['25.png', '889.png', '1446.png'],\n",
       "  'question': 'There are more green circles that are small circles',\n",
       "  'answer': 'no',\n",
       "  'task': '1small2big',\n",
       "  'image_filename': '0.png'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation[\"questions\"][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'exactly': {'no': 32000, 'yes': 32000},\n",
       "  'more': {'no': 16000, 'yes': 16000}},\n",
       " 'test': {'exactly': {'no': 4000, 'yes': 4000},\n",
       "  'more': {'no': 2000, 'yes': 2000}},\n",
       " 'val': {'exactly': {'no': 4000, 'yes': 4000},\n",
       "  'more': {'no': 2000, 'yes': 2000}}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'1small2big': 48000, '1big2small': 48000},\n",
       " 'test': {'1small2big': 6000, '1big2small': 6000},\n",
       " 'val': {'1small2big': 6000, '1big2small': 6000}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {('circle', 'green'): 800,\n",
       "  ('triangle', 'white'): 800,\n",
       "  ('rectangle', 'white'): 800,\n",
       "  ('circle', 'red'): 800,\n",
       "  ('square', 'yellow'): 800,\n",
       "  ('circle', 'yellow'): 800,\n",
       "  ('square', 'blue'): 800,\n",
       "  ('triangle', 'red'): 800,\n",
       "  ('circle', 'white'): 800,\n",
       "  ('circle', 'blue'): 800,\n",
       "  ('rectangle', 'green'): 800,\n",
       "  ('square', 'white'): 800,\n",
       "  ('rectangle', 'yellow'): 800,\n",
       "  ('square', 'green'): 800,\n",
       "  ('rectangle', 'red'): 800,\n",
       "  ('triangle', 'yellow'): 800,\n",
       "  ('square', 'red'): 800,\n",
       "  ('triangle', 'blue'): 800,\n",
       "  ('triangle', 'green'): 800,\n",
       "  ('rectangle', 'blue'): 800},\n",
       " 'test': {('circle', 'green'): 100,\n",
       "  ('triangle', 'white'): 100,\n",
       "  ('rectangle', 'white'): 100,\n",
       "  ('circle', 'red'): 100,\n",
       "  ('square', 'yellow'): 100,\n",
       "  ('circle', 'yellow'): 100,\n",
       "  ('square', 'blue'): 100,\n",
       "  ('triangle', 'red'): 100,\n",
       "  ('circle', 'white'): 100,\n",
       "  ('circle', 'blue'): 100,\n",
       "  ('rectangle', 'green'): 100,\n",
       "  ('square', 'white'): 100,\n",
       "  ('rectangle', 'yellow'): 100,\n",
       "  ('square', 'green'): 100,\n",
       "  ('rectangle', 'red'): 100,\n",
       "  ('triangle', 'yellow'): 100,\n",
       "  ('square', 'red'): 100,\n",
       "  ('triangle', 'blue'): 100,\n",
       "  ('triangle', 'green'): 100,\n",
       "  ('rectangle', 'blue'): 100},\n",
       " 'val': {('circle', 'green'): 100,\n",
       "  ('triangle', 'white'): 100,\n",
       "  ('rectangle', 'white'): 100,\n",
       "  ('circle', 'red'): 100,\n",
       "  ('square', 'yellow'): 100,\n",
       "  ('circle', 'yellow'): 100,\n",
       "  ('square', 'blue'): 100,\n",
       "  ('triangle', 'red'): 100,\n",
       "  ('circle', 'white'): 100,\n",
       "  ('circle', 'blue'): 100,\n",
       "  ('rectangle', 'green'): 100,\n",
       "  ('square', 'white'): 100,\n",
       "  ('rectangle', 'yellow'): 100,\n",
       "  ('square', 'green'): 100,\n",
       "  ('rectangle', 'red'): 100,\n",
       "  ('triangle', 'yellow'): 100,\n",
       "  ('square', 'red'): 100,\n",
       "  ('triangle', 'blue'): 100,\n",
       "  ('triangle', 'green'): 100,\n",
       "  ('rectangle', 'blue'): 100}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "from ipywidgets import widgets, HBox\n",
    "from random import randrange\n",
    "\n",
    "split = \"train\"\n",
    "\n",
    "with open(annotations_path + split + \".json\") as f:\n",
    "    dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are more red squares that are big squares\n",
      "yes\n",
      "1small2big\n"
     ]
    }
   ],
   "source": [
    "random_sample_id = randrange(len(dataset[\"questions\"]) + 1)\n",
    "\n",
    "image_filename = dataset[\"questions\"][random_sample_id][\"image_filename\"]\n",
    "\n",
    "img = Image.open(images_path + split + \"/\" + image_filename)\n",
    "\n",
    "print(dataset[\"questions\"][random_sample_id][\"question\"])\n",
    "print(dataset[\"questions\"][random_sample_id][\"answer\"])\n",
    "print(dataset[\"questions\"][random_sample_id][\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5810f2ef24313bd9c92bd9c9ac884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\xc6\\x00\\x00\\x05\\xc6\\x08\\x06\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_path_orig = \"malevic/data/pos1/images/\" + split + \"/\"\n",
    "\n",
    "img2 = [widgets.Image(value = open(images_path_orig + x, 'rb').read()) \n",
    "       for x in dataset[\"questions\"][random_sample_id][\"images\"]]\n",
    "    \n",
    "hbox = HBox([img2[0], img2[1], img2[2]])\n",
    "display(hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=960x240 at 0x1A080005888>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_index': 40052,\n",
       " 'image_index': 6675,\n",
       " 'images': ['9275.png', '1796.png', '1696.png'],\n",
       " 'question': 'There are more red squares that are big squares',\n",
       " 'answer': 'yes',\n",
       " 'task': '1small2big',\n",
       " 'image_filename': '6675.png'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"questions\"][random_sample_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create big nlvr-like scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55207987/is-there-any-way-to-merge-multiple-image-into-one-single-image-in-python\n",
    "\n",
    "class Montage(object):\n",
    "    def __init__(self,initial_image):\n",
    "        self.montage = initial_image\n",
    "        self.x,self.y = self.montage.shape[:2]\n",
    "\n",
    "    def append(self,image):\n",
    "        image = image[:,:,:3]\n",
    "        x,y = image.shape[0:2]\n",
    "        new_image = cv2.resize(image,(int(y*float(self.x)/x),self.x))\n",
    "        self.montage = np.hstack((self.montage,new_image))\n",
    "\n",
    "    def save(self, filename):\n",
    "        cv2.imwrite(filename, self.montage) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = cv2.imread(\"separator.png\")\n",
    "\n",
    "for split in datasplits:\n",
    "    \n",
    "    images_path = \"malevic/data/pos1/images/\" + split + \"/\"\n",
    "    \n",
    "    with open(annotations_path + \"/\" + split + \".json\") as f:\n",
    "        annotation = json.load(f)\n",
    "        \n",
    "    for sample in annotation[\"questions\"]:\n",
    "\n",
    "        sampled_imgs = sample[\"images\"]\n",
    "\n",
    "        if sample[\"question_index\"] % 6 == 0:\n",
    "            images = [cv2.imread(images_path + x)[:,:,:3] for x in sampled_imgs]\n",
    "            \n",
    "            img_id = sample[\"image_index\"]\n",
    "\n",
    "            if img_id % 3 == 0:\n",
    "                m = Montage(images[0])\n",
    "                m.append(sep)\n",
    "                m.append(images[1])\n",
    "                m.append(sep)\n",
    "                m.append(images[2])\n",
    "            elif img_id % 3 == 1:\n",
    "                m = Montage(images[1])\n",
    "                m.append(sep)\n",
    "                m.append(images[0])\n",
    "                m.append(sep)\n",
    "                m.append(images[2])\n",
    "            else:\n",
    "                m = Montage(images[1])\n",
    "                m.append(sep)\n",
    "                m.append(images[2])\n",
    "                m.append(sep)\n",
    "                m.append(images[0])\n",
    "\n",
    "            m.save(\"dataset-balanced/images_big_upd/\" + split + \"/\" + sample['image_filename'])\n",
    "            \n",
    "            resized = Image.open(\"dataset-balanced/images_big_upd/\" + split + \"/\" + sample['image_filename']).resize((960, 240))\n",
    "            tmp = np.asarray(resized)\n",
    "            plt.imsave(\"dataset-balanced/images_upd/\" + split + \"/\" + sample['image_filename'], tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import shutil\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    \n",
    "    malevic_folder = \"malevic/data/pos1/images/\" + split + \"/\"\n",
    "    \n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\") as f:\n",
    "        annotation = json.load(f)\n",
    "    \n",
    "    for datum in annotation[\"questions\"]:\n",
    "        datum[\"images_shuffled\"] = datum[\"images\"].copy()\n",
    "        shuffle(datum[\"images_shuffled\"])\n",
    "        datum[\"nlvr2_ids\"] = []\n",
    "        \n",
    "        for i, img_path in enumerate(datum[\"images_shuffled\"]):\n",
    "            new_img_path = str(datum['image_index']) + \"-img\" + str(i) + \".png\"\n",
    "            if datum['question_index'] % 6 == 0:\n",
    "                shutil.copy(malevic_folder + img_path, \"dataset-balanced/nlvr2/\" + split + \"/\" + new_img_path)\n",
    "            \n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\", \"w\") as f:\n",
    "        json.dump(annotation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in datasplits:\n",
    "    \n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\") as f:\n",
    "        annotation = json.load(f)\n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\") as f:\n",
    "    annotation = json.load(f)\n",
    "        \n",
    "    new_data = []\n",
    "    for i, datum in enumerate(annotation[\"questions\"]):\n",
    "        new_datum = {\n",
    "            'identifier': datum['image_index'],\n",
    "            'img0': datum[\"nlvr2_ids\"][0].split('.')[0],\n",
    "            'img1': datum[\"nlvr2_ids\"][1].split('.')[0],\n",
    "            'img2': datum[\"nlvr2_ids\"][2].split('.')[0],\n",
    "            'label': 1 if datum['answer'] == 'yes' else 0,\n",
    "            'sent': datum['question'],\n",
    "            'uid': 'nlvr2_%s_%d' % (split, i),\n",
    "        }\n",
    "        new_data.append(new_datum)\n",
    "        \n",
    "    with open('dataset-balanced/nlvr2/%s.json' % split, 'w') as g:\n",
    "        json.dump(new_data, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for split in datasplits:\n",
    "\n",
    "    directory = \"dataset-balanced/nlvr2/\" + split + \"/\"\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".png\"): \n",
    "            resized = Image.open(directory + filename).resize((350, 350))\n",
    "            tmp = np.asarray(resized)\n",
    "            plt.imsave(directory + filename, tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate datasets by statement and tasks type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for split in ['test', 'train', 'valid']:\n",
    "    \n",
    "    new_data_exactly = []\n",
    "    new_data_more = []\n",
    "    \n",
    "    with open('dataset-balanced/nlvr2/%s.json' % split) as g:\n",
    "        #json.dump(new_data, g, sort_keys=True, indent=4)\n",
    "        data = json.load(g)\n",
    "        \n",
    "    for datum in data:\n",
    "        if datum['sent'].split()[2] == 'more':\n",
    "            new_data_more.append(datum)\n",
    "        elif datum['sent'].split()[2] == 'exactly':\n",
    "            new_data_exactly.append(datum)\n",
    "                \n",
    "    with open('dataset-balanced/nlvr2/%s_more.json' % split, \"w\") as g:\n",
    "        json.dump(new_data_more, g, sort_keys=True, indent=4)\n",
    "    with open('dataset-balanced/nlvr2/%s_exactly.json' % split, \"w\") as g:\n",
    "        json.dump(new_data_exactly, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for split in ['test', 'train', 'valid']:\n",
    "    \n",
    "    new_data = []\n",
    "    \n",
    "    with open('dataset-balanced/nlvr2/%s.json' % split) as g:\n",
    "        #json.dump(new_data, g, sort_keys=True, indent=4)\n",
    "        data = json.load(g)\n",
    "        \n",
    "    for datum in data:\n",
    "        new_datum = {}\n",
    "        new_datum['identifier'] = datum['identifier']\n",
    "        new_datum['img0'] = str(datum['identifier'])\n",
    "        new_datum['sent'] = datum['sent']\n",
    "        new_datum['label'] = datum['label']\n",
    "        new_datum['uid'] = datum['uid']\n",
    "        \n",
    "        new_data.append(new_datum)\n",
    "                \n",
    "    with open('dataset-balanced/nlvr2/upd/%s.json' % split, \"w\") as g:\n",
    "        json.dump(new_data, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for split in ['test', 'train', 'valid']:\n",
    "    \n",
    "    new_data_more = []\n",
    "    new_data_exactly = []\n",
    "    \n",
    "    with open('dataset-balanced/nlvr2/upd/%s.json' % split) as g:\n",
    "        #json.dump(new_data, g, sort_keys=True, indent=4)\n",
    "        data = json.load(g)\n",
    "        \n",
    "    for datum in data:\n",
    "        if datum['sent'].split()[2] == 'more':\n",
    "            new_data_more.append(datum)\n",
    "        elif datum['sent'].split()[2] == 'exactly':\n",
    "            new_data_exactly.append(datum)\n",
    "                \n",
    "    with open('dataset-balanced/nlvr2/upd/%s_more.json' % split, \"w\") as g:\n",
    "        json.dump(new_data_more, g, sort_keys=True, indent=4)\n",
    "    with open('dataset-balanced/nlvr2/upd/%s_exactly.json' % split, \"w\") as g:\n",
    "        json.dump(new_data_exactly, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in datasplits:\n",
    "    \n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\") as f:\n",
    "        annotation = json.load(f)\n",
    "        \n",
    "    new_data_1small = []\n",
    "    new_data_1big = []\n",
    "    \n",
    "    si = 0\n",
    "    bi = 0\n",
    "    \n",
    "    for datum in annotation[\"questions\"]:\n",
    "        new_datum = {\n",
    "            'identifier': datum['image_index'],\n",
    "            'img': str(datum['image_index']),\n",
    "            'img0': datum[\"nlvr2_ids\"][0].split('.')[0],\n",
    "            'img1': datum[\"nlvr2_ids\"][1].split('.')[0],\n",
    "            'img2': datum[\"nlvr2_ids\"][2].split('.')[0],\n",
    "            'label': 1 if datum['answer'] == 'yes' else 0,\n",
    "            'sent': datum['question'],\n",
    "        }\n",
    "        if datum['task'] == '1small2big':\n",
    "            new_datum['uid'] = 'nlvr2_%s_%d' % (split, si)\n",
    "            new_data_1small.append(new_datum)\n",
    "            si += 1\n",
    "        elif datum['task'] == '1big2small':\n",
    "            new_datum['uid'] = 'nlvr2_%s_%d' % (split, bi)\n",
    "            new_data_1big.append(new_datum)\n",
    "            bi += 1\n",
    "        \n",
    "#     with open('dataset-balanced/nlvr2/%s.json' % split, 'w') as g:\n",
    "#         json.dump(new_data, g, sort_keys=True, indent=4)\n",
    "\n",
    "    with open('dataset-balanced/nlvr2/1small2big/%s.json' % split, 'w') as g:\n",
    "            json.dump(new_data_1small, g, sort_keys=True, indent=4)\n",
    "    with open('dataset-balanced/nlvr2/1big2small/%s.json' % split, 'w') as g:\n",
    "            json.dump(new_data_1big, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in datasplits:\n",
    "    \n",
    "    with open(annotations_path + \"/\" + split + \"_nlvr2.json\") as f:\n",
    "        annotation = json.load(f)\n",
    "        \n",
    "    new_data = []\n",
    "    \n",
    "    for i, datum in enumerate(annotation[\"questions\"]):\n",
    "        new_datum = {\n",
    "            'identifier': datum['image_index'],\n",
    "            'img': str(datum['image_index']),\n",
    "            'img0': datum[\"nlvr2_ids\"][0].split('.')[0],\n",
    "            'img1': datum[\"nlvr2_ids\"][1].split('.')[0],\n",
    "            'img2': datum[\"nlvr2_ids\"][2].split('.')[0],\n",
    "            'label': 1 if datum['answer'] == 'yes' else 0,\n",
    "            'sent': datum['question'],\n",
    "            'uid': 'nlvr2_%s_%d' % (split, i)\n",
    "        }\n",
    "        new_data.append(new_datum)\n",
    "\n",
    "    with open('dataset-balanced/nlvr2/final_all/%s.json' % split, 'w') as g:\n",
    "            json.dump(new_data, g, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
